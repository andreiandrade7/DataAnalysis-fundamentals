# DataAnalysis-fundamentals
Work developed in the scope of "Fundamentals of Data Analysis" module
# Fundamental of Data analysis 
**READ ME file **

by Andreia Santos
Student Id: G00425673
DATE: January, 3rd 2024



## =============================== TASKs =====================================

Task 1:
Collatz algorithm

Task 2:
Types of variables on  penguins.csv dataset


Task 3:
Review the probability density functions and select the most suitable type for each variable in the penguins dataset. Normal probability density function is recommended for the continuous variables. For categorical variables, multinomial is suggested for "species" and "islands," while binomial is recommended for "sex". 

Task 4:

It calculates entropy for various probabilities of obtaining heads in coin flips. Then, it illustrates on a graph how entropy fluctuates with the likelihood of getting heads, ranging from nearly zero to nearly certain


Task 5:

Plot all the variables in suitable graphs:

For numerical variables: Create histograms with a probability density function using the normal distribution.
For categorical variables: Generate bar plots for each of the three variables


## =============================== PROJECT =====================================

### Executive Summary:
    The repository contains Python code analyzing the Iris dataset with details on 150 flowers across three species: Setosa, Versicolor, and Virginica. Each species has 50 flowers, and the dataset logs four numerical descriptors (sepal length, sepal width, petal length, and petal width) for every flower.


### Purpose:
    The code conducts exploratory data analysis (EDA) on the Iris dataset, aiming to:


### Characterize the dataset's variables and their types.
    Clean the dataset to handle missing values (if any).
    Perform mathematical descriptions of the continuous variables.
    Visualize relationships between variables and explore their impact on flower species using graphs and statistical summaries.
    Instructions to Close and Run Code/Notebooks:


### Setup:
    Confirm the presence of Python on your system. 
    The Jupiter notebook can be run on Visual Studio Code Software or run online following the instruction on https://jupyter.org/try-jupyter/notebooks/?path=notebooks/Intro.ipynb
    Repository must be cloned or download prior to the accessement  from the provided URL.
    Install the necessary libraries: pandas, matplotlib, seaborn, and scikit-learn.


### Run the Code:

    Access the Python script or Jupyter Notebook containing the code.
    Verify that the 'iris.csv' dataset file is located in the code's directory.
    Execute the code cells in sequence to observe the analysis and visualizations.


### Understanding the Analysis:

    The code first imports necessary libraries and loads the Iris dataset.

    It assesses variable types, scans for any missing data, and conducts statistical analyses (e.g., minimum, maximum, average, percentiles) on the numerical variables.
    The visualizations comprise correlation matrices, scatter plots, histograms, box plots, violin plots, and line charts, aiding in comprehending relationships and distributions among variables.
    The interpretation phase covers findings on correlations, dataset distributions, and class-specific variations derived from these visualizations.


### Closing the Code/Notebook:

    Save any changes made during the analysis.
    Close the code editor or Jupyter Notebook.


### Additional Notes:

  The code comments and markdown sections offer comprehensive explanations for each step of the analysis.
